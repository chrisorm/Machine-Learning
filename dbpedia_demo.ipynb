{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#download from here https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz",
    "dbpedia = pd.read_csv('data/dbpedia_csv/train.csv', header=None)\n",
    "train_X = dbpedia[2]\n",
    "train_y = dbpedia[0]\n",
    "dbpedia = pd.read_csv('data/dbpedia_csv/test.csv', header=None)\n",
    "test_X = dbpedia[2]\n",
    "test_y = dbpedia[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_len = train_X.apply(lambda x: len(x.split(' '))).get_values()\n",
    "test_len = test_X.apply(lambda x: len(x.split(' '))).get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_processor=tf.contrib.learn.preprocessing.VocabularyProcessor(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X_t = vocab_processor.fit_transform(train_X)\n",
    "test_X_t = vocab_processor.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = np.array(list(train_X_t))\n",
    "test_X = np.array(list(test_X_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batcher(num_samples,size):\n",
    "    idx = np.random.choice(np.arange(num_samples), batch_size)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "vocabulary_size = len(vocab_processor.vocabulary_)\n",
    "embed_size=100\n",
    "n_classes=15\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    raw_y=tf.placeholder(tf.int64, shape=[batch_size])\n",
    "    tf_y = tf.one_hot(raw_y,15, dtype=tf.int64)\n",
    "    tf_X = tf.placeholder(tf.int64, shape=[batch_size, 50])\n",
    "    tf_lens = tf.placeholder(tf.int64, shape=[batch_size])\n",
    "    \n",
    "    embeddings = tf.Variable(tf.random_uniform([vocabulary_size,embed_size],-1.0,1.0)) \n",
    "    t_embed = tf.nn.embedding_lookup(embeddings, tf_X) #shape [batch_size, seq_length, embedding_size]\n",
    "    s_embed = tf.unstack(t_embed,axis=1) # list of [batch_size, embedding_size]\n",
    "    cell = tf.contrib.rnn.LSTMCell(num_units=embed_size)\n",
    "    #outputs,state = tf.contrib.rnn.static_rnn(cell, s_embed, dtype=tf.float32)\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell, t_embed, sequence_length=tf_lens, dtype=tf.float32)\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal([embed_size,n_classes]))\n",
    "    bias = tf.Variable(tf.random_uniform([n_classes], -1.0,1.0))\n",
    "    logits = tf.add(tf.matmul(state.h, weights), bias)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_y, logits=logits))\n",
    "    opt = tf.train.AdamOptimizer(0.005).minimize(loss)\n",
    "    \n",
    "    predictions=tf.argmax(tf.nn.softmax(logits),1)\n",
    "    correct_prediction = tf.equal(raw_y, predictions)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    init_op = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss: 0.00571637988091\n",
      "accuracy 0.820313\n",
      "[ 2 10  6  9  5  1  5 11 11  1  6 12  7  7  5  6 11 12 10  6  8  6  8  3 12\n",
      " 14 13  6  2  6  4 10  7  3 10  6  5  6 10  5  6  9  6  9  5 14  5 11  5  7\n",
      " 12  8  7  6  2 11 11 13  4  5 13  8  2  4 12  6  4  5 11  4 12 13  7 11 12\n",
      "  9  4  6  7  4  9 12  2 14  6 10  6  4  2  1  9 13 14 10 11  6 10 14  6  8\n",
      "  4 13 13 13  9  3 10  4 11 10  4 12  6 10 13  1  5  3 12  1  1  8  3  4  5\n",
      "  5  2  9]\n",
      "[ 2 11  6  9  3  1  3 11 11  1  6 12  7  1  5  6 11 12 11  6  8  9  8  3 12\n",
      " 14 13  6  2  6  4 10  2  3 10  6  5  6 10  5  7  9  1  8  5 14 11 11  1  7\n",
      " 12  8  7  6  2 11 11 13  3  5 13  8  2  4 12  6  4  5 11  4 12 13  7 11 12\n",
      "  9  4  6  7  4  9 12  2 14  6 10  1  4  2 10  9 13 13 11 11  6 11 14  6  8\n",
      "  4 13 13 13  9  3 10  3 11 10  4 12  6 10 13  1  5 11 12  8  7  8  3  4  1\n",
      "  5  2  9]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "average loss: 0.00251570433378\n",
      "accuracy 0.898438\n",
      "[ 5  5 13 14  3 13  8  6  7 14  6  6 12  7  3 13  5 12  4  5  7  8 10  5  7\n",
      "  5 13  8  8 10  2  1  4 14 14  1 14  6 10  1  7  6  5 10  4 13 11 13 11 11\n",
      "  6  5 14 10  9 14  8  4 10 12  2  7 11  5  3  6  8 10 11  1  1  1  7  1 10\n",
      "  2 13  9  5 12  2  5  2 14  9  8  8  5  4 14 14 10 12  9 12  8 10 14  9  3\n",
      "  5  2  4 13  4  7  7 13  4 11  2 12  7  8  5  4 12 11  1 12  6  6  3 11 11\n",
      " 10  2  1]\n",
      "[ 5  5 13 14  3 13  8  6  7 14  6  6 12  7  3 13  5 12  4  5  6  8 10  5  7\n",
      "  5 13  8  8 10  2  1  4 14 14  3 14  6 10  1  8  6  5 10  4 13 11 13 11 11\n",
      "  6  5 14 10  9 14  8  4 10 12  2  1 11  3  3  6  8 10 11 14  1  1  7  1 10\n",
      "  2 13  9  5 12  2  5  2 14  9  8  8  5  4 14 14 10 12  9 12  8 10 14  9  3\n",
      "  5  2  4 14  4  2  7 13  4 11  1 12  6  8  5  4 12 10  3 12  6  6  3 11 11\n",
      " 10  2  6]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "average loss: 0.00215452283621\n",
      "accuracy 0.882813\n",
      "[ 2 13 12  9 12  9  2 13 10 13  7  7  8  7 12  6  1  6  2 11 11  9  4 14  5\n",
      " 10 13  1  8  6  7  9  2  5  7  7  3  7 14  2  3 14  7 14 11  9  6  8  7  5\n",
      "  7  6 10 11 13  5 13  3  9  4  3  9 12  1  3 10  3  4  1  3 10  4  7 14  5\n",
      "  9  5  1  8  9  9  6 12 10 11  9  7 11  8 14  8  4 13  6 13  1  1  2  7  3\n",
      "  8 14  3  3  5 11  6  6 11  1  1 14  7  2  2  1  9 13 10 11  8 13  8  5  5\n",
      "  5 13  5]\n",
      "[ 2 13 12  9 13  9  2 13 10 13  7  7  8  7 12  6  1  8  2 11 11  9  4 13  5\n",
      " 10 13  1  8  6  7  9  2  5 14  7  4  7 14  2  3 14  7 14 11  9  4  8  7  5\n",
      " 10  6 10 11 13  5 13  3  9  4  3  9 12  1  3 10  4  4  1  5 10  4  2 13  5\n",
      "  9  5  1  8  9  9  6 12 10 11  9  7 11  8 14  8  4 13  7 13  1  1  2  2  3\n",
      "  8 14  3  3  2 11  6  6 11  1  1 14  7  2  2  6  9 13 10 11  8 13  8  5  5\n",
      "  5 13  5]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "average loss: 0.00247231304646\n",
      "accuracy 0.96875\n",
      "[ 5  2  8  6  7 14 10  2 14  5  2 12  7  5  6 13  5 13  2  5 13 10 14 11  5\n",
      "  9  2 13  1  7 11  7 10  5  6  2  4  8  8  2  9  7 13  9  9  8 10 12  8  2\n",
      " 12 14 12  2  3  6  3 11 14  5 13  8 14  8  6  9  1  8  5 13 14  3  3 12  2\n",
      "  1  5  1 13  4  1 10 14  7  9 14 10  8  6  3  4  6 13 13 10  7 13  9  2 10\n",
      " 12 14 13  5  3  8 14  4  4  2 14  1 14  1  3  8  7  3 10  5  1  1 10 11  9\n",
      "  1  9  6]\n",
      "[ 5  2  8  6  7 14 10  2 14  5  2 12  7  5  6 13  5 13  2  5 13 10 14 11  5\n",
      "  9  2 13  1  7 11  7 10  5  6  2  4  8  8  2  9  7 13  9  9  8 10 12  8  2\n",
      " 12 14 12  2  3  6  3 11 14  5 13  8 14  8  6  9  1  8  5 13 14  1  3 12  2\n",
      "  6  5  1 13  4  1 10 14  7  9 14 10 10  6  3  4  6 13 13 10  7 13  9  2 10\n",
      " 12 14 13  5  3  8 14  4  4  2 14  1 14  1  3  8  7  3 10  5  1  1 10 11  9\n",
      "  7  9  6]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_steps=500\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init_op)\n",
    "    average_loss=0.0\n",
    "    for step in range(n_steps):\n",
    "        idx=batcher(train_X.shape[0],batch_size )\n",
    "        feed_dict= {tf_X:train_X[idx], raw_y:train_y[idx], tf_lens:train_len[idx]}\n",
    "        l,_=sess.run([loss, opt], feed_dict=feed_dict)\n",
    "        average_loss +=l\n",
    "        if (step>0) and (step%100==0):\n",
    "            \n",
    "            idx=batcher(test_X.shape[0],batch_size*10)\n",
    "            test_dict = {tf_X:test_X[idx], raw_y:test_y[idx], tf_lens:test_len[idx]}\n",
    "            print(\"average loss:\", l/100)\n",
    "            print(\"accuracy\",accuracy.eval(feed_dict=test_dict))\n",
    "            print(predictions.eval(feed_dict=test_dict))\n",
    "           \n",
    "            print(test_y[idx].get_values())\n",
    "            print('-'*100)\n",
    "            average_loss=0.0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
